## Shallow Security: on the Creation of Adversarial Variants to Evade Machine Learning-Based Malware Detectors (Seminar 6.1)

**NOTE**: This blog is for a special topics course at Texas A&M (ML for Cyber Defenses). During each lecture a student presents information from the assigned paper. This blog summarizes and further discusses each topic.

During this seminar, Johnny Le presented [Shallow Security: on the Creation of Adversarial Variants to Evade Machine Learning-Based Malware Detectors](https://dl.acm.org/doi/pdf/10.1145/3375894.3375898?casa_token=2AMOrMymeNUAAAAA:2_gmqLQwhwg_4iQfLEb6tXOgEc14XcyuFh0T1xm7CnwrMcDGyrUEWifi5EIZEAMCrIRi3qizZjU). After his presentation our class had an open discussion related to the paper and more. This blog post will cover a summary of the information presented as well as a summary of our class discussion.

### Presentation Summary

---
#### Introduction
- ML-based approaches are currently state-of-the-art techniques for malware detection
- They are not completely perfect, stimulating the existing arms race with attackers generating malware to exploit problems in ML-based approaches, and defenders creating new models
- Companies, such as Endgame, Inc, have formed challenges to develop better solutions to defend against adversarial attacks
  - Endgame, Inc launched a challenge to evaluate the performance of three static analysis-based ML models (with two being deep neural networks and one being a decision tree)
  - The authors of this paper participated in the challenge and bypassed all three models, while also being able to bypass real AVs as well
- The authors found drawbacks in their evaluation of the models, which were discussed during this seminar

#### The Challenge
- The competition involves completing 50 tasks by classifying distributed binaries with three models (two based on raw data and one on PE features) to earn points, with each classifier bypass earning 1 point, up to a total of 150 points
- Participants aim to create adversarial malware that mimics the original binaries' behavior in a sandboxed environment by modifying binary sections and adding data, ensuring they produce the same Indicators of Compromise (IoCs)
- Despite multiple scoreboard resets since its August 2019 start and being top performers, the team prioritized sharing their insights from investigating all samples over winning the ongoing competition, focusing on the realistic assessment of third-party ML models for malware classification
- The dataset contains 50 Portable Executable samples from 21 different malware families, aiming to represent a wide range of threats for Microsoft Windows, with an emphasis on diversity to challenge detection methods
- Four prominent malware families are highlighted
  - Emotet (5 samples): a banking trojan that steals sensitive and private information by downloading or dropping malware which spreads to other devices on the network
  - Loki (4 samples): designed for data theft (data being passwords, login credentials, and cryptocurrency wallets) and exfiltrating the stolen data to a C&C (Command and Control) host viat HTTP
  - Ramnit (4 samples): a worm capable of stealing and exfiltrating cookines, login credentials, and files to a C&C
  - Xtrat (4 samples): allows the attacker to interact with the victim via C&C servers, and enables the attackers to manage the infected machines from any connected devices such as webcameras and microphones
- The distribution and characteristics of these malware samples are analyzed using labels from VirusTotal, normalized by AVClass, demonstrating a variety of attack vectors and the need for diversified security approaches

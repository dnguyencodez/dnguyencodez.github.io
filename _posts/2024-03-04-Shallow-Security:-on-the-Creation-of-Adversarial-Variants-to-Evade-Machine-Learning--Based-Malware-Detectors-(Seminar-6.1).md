## Shallow Security: on the Creation of Adversarial Variants to Evade Machine Learning-Based Malware Detectors (Seminar 6.1)

**NOTE**: This blog is for a special topics course at Texas A&M (ML for Cyber Defenses). During each lecture a student presents information from the assigned paper. This blog summarizes and further discusses each topic.

During this seminar, Johnny Le presented [Shallow Security: on the Creation of Adversarial Variants to Evade Machine Learning-Based Malware Detectors](https://dl.acm.org/doi/pdf/10.1145/3375894.3375898?casa_token=2AMOrMymeNUAAAAA:2_gmqLQwhwg_4iQfLEb6tXOgEc14XcyuFh0T1xm7CnwrMcDGyrUEWifi5EIZEAMCrIRi3qizZjU). After his presentation our class had an open discussion related to the paper and more. This blog post will cover a summary of the information presented as well as a summary of our class discussion.

### Presentation Summary

---
#### Introduction
- ML-based approaches are currently state-of-the-art techniques for malware detection
- They are not completely perfect, stimulating the existing arms race with attackers generating malware to exploit problems in ML-based approaches, and defenders creating new models
- Companies, such as Endgame, Inc, have formed challenges to develop better solutions to defend against adversarial attacks
  - Endgame, Inc launched a challenge to evaluate the performance of three static analysis-based ML models (with two being deep neural networks and one being a decision tree)
  - The authors of this paper participated in the challenge and bypassed all three models, while also being able to bypass real AVs as well
- The authors found drawbacks in their evaluation of the models, which was discussed during this seminar

#### The Challenge
- The competition involves completing 50 tasks by classifying distributed binaries with three models (two based on raw data and one on PE features) to earn points, with each classifier bypass earning 1 point, up to a total of 150 points
- Participants aim to create adversarial malware that mimics the original binaries' behavior in a sandboxed environment by modifying binary sections and adding data, ensuring they produce the same Indicators of Compromise (IoCs)

## EvadeDroid: A Practical Evasion Attack on Machine Learning for Black-box Android Malware Detection (Seminar 8.1)

**NOTE**: This blog is for a special topics course at Texas A&M (ML for Cyber Defenses). During each lecture a student presents information from the assigned paper. This blog summarizes and further discusses each topic.

During this seminar, Colton Simpson presented [EvadeDroid: A Practical Evasion Attack on Machine Learning for Black-box Android Malware Detection]([https://ieeexplore.ieee.org/document/9685442](https://arxiv.org/pdf/2110.03301.pdf)). After their presentation our class had an open discussion related to the paper and more. This blog post will cover a summary of the information presented as well as a summary of our class discussion.

### Presentation Summary

---
#### Introduction
- ML-based defenses are vulnerable to evasion attacks, where attackers transform malware into adversarial examples
- However, the use of adversarial examples still pose some challenges
  - Manipulating feature representations of malicious Android applications may break their functionality as APK features are typically discrete instead of continuous
    - A possible solution is to extract features from the Android Manifest file
    - There is questionable practicality as executability of the original apps is not guaranteed, preprocessing techniques can discard features added to the Manifest file, and advanced Android malware detectors rely on the semantics of Android apps rather than Manifest files
  - Feature mapping in Android app security is irreversible, preventing direct conversion of feature-space changes into malicious app modifications
    -  Adversaries use feature-space manipulations to craft evasion attacks, but finding corresponding real-world transformations is complex and not always straightforward
    -  Some transformations may fail to produce viable adversarial examples or introduce problematic changes that could crash the malware, diverging from attackers' intentions
  - Current methods produce adversarial examples tailored to specific malware detectors' machine learning algorithms and features, assuming attackers have perfect or limited knowledge of the classifiers
    - Realistically, attackers often have zero knowledge of malware detectors, which operate as black-boxes with some studies exploring semi-black-box approaches using feedback from the detectors
    - These methods are inefficient, requiring many queries and substantial input manipulation, which can incur costs and risk detection, and excessive alterations may compromise the malware's functionality
- To combat those issues, the authors propose EvadeDroid
- EvadeDroid is a two-step evasion technique for Android malware that first selects similar benign apps as donors to create a set of code transformations, ensuring the malware mimics benign behavior
- It uses program slicing to extract useful code snippets, or gadgets, from these donors and injects them into malware to evade machine learning classifiers while maintaining the app's functionality
- The second step involves iteratively applying these transformations to malware, guided by feedback from the target classifier, to produce altered versions that are misclassified as benign
- The contributions can be summarized as follows:
  - EvadeDroid is proposed, which is a state-of-the-art solution that successfully evades ML-based malware detectors
  - Demonstrate that EvadeDroid is a query-efficient attacker
  - The proposed attack can operate with either soft labels or hard labels
  - Evaluate EvadeDroid's performance on popular commercial antivirus products

#### Related Work
- Various studies have explored adversarial examples in the Windows domain
  - Modeling the action selection as a multi-armed bandit problem within reinforcement learning
  - Applying padding and sample injection to malware samples to bypass visualization-based malware detectors
  - Making small manipulations in file headers to generate adversarial malware
  - Perturbing API sequences of malware samples as a black-box attack
- Advancements in the Android domain have not been as significant as the same manipulations cannot be mapped to Android applications
  - All variations of existing studies require an attacker's knowledge of the system and perturbations in the problem and feature spaces
  - These perturbations do not mimic the reality of problem and feature spaces
  - It is not practical to assume that attackers have knowledge of deployed classifiers as well
  - Some studies also lack details about feature extraction methods
  - EvadeDroid addresses the limitations of existing attacks



### Discussion Summary

---
- Mention main idea of using opaque predicates, dead code, etc.
- The reason that droppers aren't used is that Android doesn't support them and that once a dropper is used, the program file is immediately reordered, and thus the dropper is not needed
  - The implementation is the same without being the same, Android uses different abstraction layers than x86, for example
  - Compiled languages have assembly instructions (C for example), but Android is built on Java which is easier to handle as there is more high level information
  - Compiled vs interpreted languages have different security implications
- The attack used in this paper is 'semi black box' as the authors know that the target model is based on code along with other information
- In theory, EvadeDroid can be used for Windows PE files
  - Implementation will be different, but the concepts will be similar such as using opaque predicates, dead code, etc.
  - The first android attacks were based on manifest files which list permissions and more
  - Attacks against manifest files (where there are boolean vectors of manifest permissions) are also possible through
- Gadgets are essential in security as they fall under return oriented programming attacks which can be used to control the stack pointers as a result of buffer overflow, leading to control of the program
- Markov decision processes (which are a chain of state action pairs while accounting for the probability of choosing the best next state, using previous state information) can also be applied to malware detection
  - Function calls, for instance, can be represented as a markov decision process by determining the probability of a function being chosen or called next.

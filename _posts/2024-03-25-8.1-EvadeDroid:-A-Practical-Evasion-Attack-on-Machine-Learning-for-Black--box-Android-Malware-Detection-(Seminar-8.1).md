## EvadeDroid: A Practical Evasion Attack on Machine Learning for Black-box Android Malware Detection (Seminar 8.1)

**NOTE**: This blog is for a special topics course at Texas A&M (ML for Cyber Defenses). During each lecture a student presents information from the assigned paper. This blog summarizes and further discusses each topic.

During this seminar, Colton Simpson presented [EvadeDroid: A Practical Evasion Attack on Machine Learning for Black-box Android Malware Detection]([https://ieeexplore.ieee.org/document/9685442](https://arxiv.org/pdf/2110.03301.pdf)). After their presentation our class had an open discussion related to the paper and more. This blog post will cover a summary of the information presented as well as a summary of our class discussion.

### Presentation Summary

---
#### Introduction
- ML-based defenses are vulnerable to evasion attacks, where attackers transform malware into adversarial examples
- However, the use of adversarial examples still pose some challenges
  - Manipulating feature representations of malicious Android applications may break their functionality as APK features are typically discrete instead of continuous
    - A possible solution is to extract features from the Android Manifest file
    - There is questionable practicality as executability of the original apps is not guaranteed, preprocessing techniques can discard features added to the Manifest file, and advanced Android malware detectors rely on the semantics of Android apps rather than Manifest files
  - Feature mapping in Android app security is irreversible, preventing direct conversion of feature-space changes into malicious app modifications
    -  Adversaries use feature-space manipulations to craft evasion attacks, but finding corresponding real-world transformations is complex and not always straightforward
    -  Some transformations may fail to produce viable adversarial examples or introduce problematic changes that could crash the malware, diverging from attackers' intentions
  - Current methods produce adversarial examples tailored to specific malware detectors' machine learning algorithms and features, assuming attackers have perfect or limited knowledge of the classifiers
    - Realistically, attackers often have zero knowledge of malware detectors, which operate as black-boxes with some studies exploring semi-black-box approaches using feedback from the detectors
    - These methods are inefficient, requiring many queries and substantial input manipulation, which can incur costs and risk detection, and excessive alterations may compromise the malware's functionality
- To combat those issues, the authors propose EvadeDroid
- EvadeDroid is a two-step evasion technique for Android malware that first selects similar benign apps as donors to create a set of code transformations, ensuring the malware mimics benign behavior
- It uses program slicing to extract useful code snippets, or gadgets, from these donors and injects them into malware to evade machine learning classifiers while maintaining the app's functionality
- The second step involves iteratively applying these transformations to malware, guided by feedback from the target classifier, to produce altered versions that are misclassified as benign
- The contributions can be summarized as follows:
  - EvadeDroid is proposed, which is a state-of-the-art solution that successfully evades ML-based malware detectors
  - Demonstrate that EvadeDroid is a query-efficient attacker
  - The proposed attack can operate with either soft labels or hard labels
  - Evaluate EvadeDroid's performance on popular commercial antivirus products

#### Related Work
- Various studies have explored adversarial examples in the Windows domain
  - Modeling the action selection as a multi-armed bandit problem within reinforcement learning
  - Applying padding and sample injection to malware samples to bypass visualization-based malware detectors
  - Making small manipulations in file headers to generate adversarial malware
  - Perturbing API sequences of malware samples as a black-box attack
- Advancements in the Android domain have not been as significant as the same manipulations cannot be mapped to Android applications
  - All variations of existing studies require an attacker's knowledge of the system and perturbations in the problem and feature spaces
  - These perturbations do not mimic the reality of problem and feature spaces
  - It is not practical to assume that attackers have knowledge of deployed classifiers as well
  - Some studies also lack details about feature extraction methods
  - EvadeDroid addresses the limitations of existing attacks

#### Proposed Attack

##### Threat Model of EvadeDroid
- Adversarial goal:
  - To manipulate Android malware samples in successfully deceiving static ML-based malware detectors
  - Trick classifiers into classifying malware samples as benign
- Adversarial knowledge:
  - Black-box access restricts EvadeDroid from knowing the training data, feature set, and classification model
  - The attacker can only query the target classifier to obtain results
- Adversarial capabilities:
  - The attack manipulates the Android malware apps through Android gadgets (slices of benign app bytecode) where the gadgets are optimized through the queries
  - The manipulation process of a malware app is performed gradually to best resemble benign apps
  - Minimal number of gadgets are inserted from the benign apps into the malware apps
  - EvadeDroid must follow two constraints:
    - Number of queries: EvadeDroid aims to generate adversarial examples with a minimal amount of queries
    - Size of adversarial payloads: EvadeDroid aims to minimize the size of injected adversarial payloads
  - Gadgets:
    - Gadgets contain an organ (slice of program functionality), an entry point to the organ, and a vein (execution path leading to the entry point)
    - EvadeDroid identifies entry points as API calls through string analysis, and uses them to extract gadgets from benign apps
    - The assumption is that the API calls of benign apps are fully functional
    - Gadget injection is successful when the loss of the injected app increases and the size of adversarial payload is the same as before
- Defender's capabilities:
  - Targe models cannot perform online learning through using EvadeDroid's adversarial examples
  - Defender cannot detect and block queries from EvadeDroid due to suspicion

##### Problem Definition
- Essentially, the objective of EvadeDroid is to generate an adversarial example that can trick the target classifier
- This must be accomplished via the attacker-defined constraints:
  - A minimal sequence of transformations
  - At a maximum number of queries
  - An a maximum adversarial payload size
- The adversarial payload size is the relative increase in the size of a malware sample applying a transformation

##### Methodology
- The proposed attack is achieved through an iterative and incremental algorithm
- Problem space transformations, satisfying problem-space constraints, are used to generate real-world adversarial samples
- The transformations are extracted from benign apps that are similar to malware apps using n-gram-based similarity
- Random-search is used to optimize the manipulation of apps
- App manipulations are incremented during the optimization process, with a sequence of transformations being applied in different iterations
- n-grams:
  - n-Grams are sequences of 'n' contiguous items used to capture patterns within texts or programs, analyzing frequencies of unique sequences
  - In malware detection, n-grams help extract feature sequences from malware binaries or source code for analysis
  - For Android malware, n-grams analyze opcodes in disassembled DEX files of APKs, extracting patterns from smali file functions for static analysis

### Discussion Summary

---
- Mention main idea of using opaque predicates, dead code, etc.
- The reason that droppers aren't used is that Android doesn't support them and that once a dropper is used, the program file is immediately reordered, and thus the dropper is not needed
  - The implementation is the same without being the same, Android uses different abstraction layers than x86, for example
  - Compiled languages have assembly instructions (C for example), but Android is built on Java which is easier to handle as there is more high level information
  - Compiled vs interpreted languages have different security implications
- The attack used in this paper is 'semi black box' as the authors know that the target model is based on code along with other information
- In theory, EvadeDroid can be used for Windows PE files
  - Implementation will be different, but the concepts will be similar such as using opaque predicates, dead code, etc.
  - The first android attacks were based on manifest files which list permissions and more
  - Attacks against manifest files (where there are boolean vectors of manifest permissions) are also possible through
- Gadgets are essential in security as they fall under return oriented programming attacks which can be used to control the stack pointers as a result of buffer overflow, leading to control of the program
- Markov decision processes (which are a chain of state action pairs while accounting for the probability of choosing the best next state, using previous state information) can also be applied to malware detection
  - Function calls, for instance, can be represented as a markov decision process by determining the probability of a function being chosen or called next.

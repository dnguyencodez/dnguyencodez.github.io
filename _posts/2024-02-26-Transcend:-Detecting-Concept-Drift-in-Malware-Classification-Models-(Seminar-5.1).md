## Transcend: Detecting Concept Drift in Malware Classification Models (Seminar 5.1)

**NOTE**: This blog is for a special topics course at Texas A&M (ML for Cyber Defenses). During each lecture a student presents information from the assigned paper. This blog summarizes and further discusses each topic.

During this seminar, Ali Ayati presented [Transcend: Detecting Concept Drift in Malware Classification Models](https://www.usenix.org/system/files/conference/usenixsecurity17/sec17-jordaney.pdf). After his presentation our class had an open discussion related to the paper and more. This blog post will cover a summary of the information presented as well as a summary of our class discussion.

### Presentation Summary

---
- Probability of fit is a well known approach for qualitative assessment of decicisions of a learning model
  - Probabilities must sum to 1 so there is a high chance of results being skewed
- New assessment techniques (conformal evaluator) have been developed that analyze objects statistically rather than probabilistically
- As opposed to probablistic measures, statistical assessment covers how likely a test object will belong to a class compared to all of its other members

#### Non-Conformity Measure
- Non-conformity measure is a scoring function that measures the difference between a group of objects belonging to the same class
  - In essence, it evaluates how "strange" a prediction is according to the different possibilities available
- For example, in SVM the non-conformity measure is the distance of a test sample from the decision boundary
  - If a new malware sample lies close to the decision boundary, it has a high non-conformity score (SVM is not certain that it belongs more to class 1 or class 2)
- Another example: for random forest, the non-conformity score can be computed using the proportion of decision trees that classify a sample as malware
  - If 40% of the trees classify a new test sample as class 1 and 60% classify as class 2, then there is a high non-conformity score
  - The sample does not conform to the majority of either class
  - If 90% of the trees classify as class 1, then the sample likely highly conforms to class 1 data

#### P-Value as a Similarity Metric
- Measures how well a sample fits into a single class
  - P-value of an object is the proportion of objects in the class that are at least as dissimilar to other objects in the set as itself
  - Conformal evaluator computes a p-value for each class, for each test element
- It is essentially the ratio between the number of training elements that are more dissimilar than the element under test

#### P-Values vs Probabilities
- Probabilities must sum to 1.0
  - If probabilities are used for decision assessment, then an incorrect conclusion might be reached for previously unseen samples
- P-values are not constrained by the same limitations
  - It is possible for two p-values to be low for the case of a previously unseen sample
- When computing probability for a test sample, only the information belonging to the test samples are used (distance to a hyperplane, for example)
- P-value is computed by comparing the scores of all samples in the class

#### Transcend
- Transcend uses two techniques to evaluate the quality of an algorithm employed on a given dataset
- The first is decision assessment, which evaluates the robustness of predictions made by the algorithm
  - 

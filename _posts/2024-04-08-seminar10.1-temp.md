### Discussion Summary

---
- Main problem in this paper is to not only find the bugs, but repair the bugs
- LLMs know how to code, therefore people expect them to fix code
  - Not always true
  - However, the assumption is if the LLM knows how to code, then it knows when its code is wrong
  - The assumption is again not always true, but as demonstrated in this paper, the LLM was successful 7/12 times
- The use of LLMs is not perfect but has extremely high potential
- Prior to LLMs how were bugs found?
  - Code analysis
  - Fuzzing (generate random inputs to trigger certain paths that makes the model or program crash)
  - Fuzzers virtually have not context of the model or program
  - LLMs are much more accessible
  - Regression testing: piece of a pipeline that ensures that there are no new bugs or erros when a new feature is pushed/updated
  - We should also perform security regression testing (something to be developed for software engineering)
- This past weekend (3/30-4/1) had news of a very impressive backdoor attack in XZ (a compression tool)
  - Bug was there for two years, found by comprimising a legitimate account and discovering it
  - Discovered by accident because someone was benchmarking compression algorithms
  - This linux XZ would have been deployed for everyone using SSH
- How efficient should LLMs be?
  - They don't need to be perfect as long as they are better than humans in the future
- Bugs that can be found in HDL
  - Logic description (of the functionality)
  - Race conditions
  - Deadlocks
  - Glitches in hardware (logic bits shifting), sometimes due to silicon not being perfect
  - LLMs can't detect those problems, thus other verification tools needed
- Pipeline of solutions is the way to go
